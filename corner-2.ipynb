{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "corner.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8tu0yUiuv4l5"
      },
      "source": [
        "## Initialize and import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "colab = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import numpy.ma as ma\n",
        "import pandas as pd\n",
        "from time import time, sleep\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.measure import LineModelND, ransac\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import DBSCAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# can be removed but here for testing\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "matplotlib.rcParams['figure.figsize'] = (18.0, 10.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_ids = ['1ROwe7mg7bdnCdMN6oEyULyWFDH192EQS', # capture1\n",
        "            '1FJmKxbfjTUn2d3V8am2GPN4jTlDsrgP-', # capture2\n",
        "            '1t4Ax303itok3L8i2BmH1vvu8oPmg2Ei2', # capture3\n",
        "            '1AF_ED0R2J-gp_q9rajptRpsbfK6baabF', # scan-data-Room1\n",
        "            '1F8W6Gmkc95Z9z836AxmWaSYdDJ0S3LsF', # scan-data-Room2\n",
        "            '1myqcdiu4IkGxUWKAvi6hD8KIJzybzHdp', # scan-data-Room1-upto-50times\n",
        "            '1UzzoG408Vkpy2Y6EfMkh9LIaSaJae8P4'] # scan-data-Room2-upto-50times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for id in data_ids:\n",
        "    os.system('gdown https://drive.google.com/uc?id=%s' % id)\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dSkZmiqQv-pa"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "## Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# read data csv\n",
        "def read_capture(file_path, verbose=True):\n",
        "    df = pd.read_csv(file_path,delimiter=',',header=None)\n",
        "    angle = df.values[:,0]\n",
        "    distance = df.values[:,1]\n",
        "    cartesian = [( r*math.sin(phi*math.pi/180),r*math.cos(phi*math.pi/180)) for r, phi in zip(distance, angle)]\n",
        "\n",
        "    x, y = map(list, zip(*cartesian))\n",
        "    x = np.array(x)\n",
        "    y = np.array(y)\n",
        "\n",
        "    x_data = x.reshape(-1, 1)\n",
        "    y_data = y.reshape(-1, 1)\n",
        "\n",
        "    plt.plot(x_data, y_data, '.', color = 'grey')\n",
        "    plt.title('All Data')\n",
        "    plt.axis('equal')\n",
        "    plt.show()\n",
        "    \n",
        "    return x_data, y_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get best RANSAC fit and compute angle\n",
        "def compute_ransac_angles(x_data, y_data, n_win=10, n_trials=100):\n",
        "\n",
        "    # storage of angles\n",
        "    angs = []\n",
        "\n",
        "    startTime = time()\n",
        "\n",
        "    # loop through data\n",
        "    # TODO: Performance edge cases. It would be unfortunate to start our data stream at a corner\n",
        "    for idx in range(len(y_data)-n_win):\n",
        "\n",
        "        # cut window\n",
        "        x_curs = x_data[idx:idx+n_win]\n",
        "        y_curs = y_data[idx:idx+n_win]\n",
        "\n",
        "\n",
        "        # setup RANSAC\n",
        "        model_LMND = LineModelND()\n",
        "        points = np.column_stack([x_curs, y_curs])\n",
        "        model_LMND.estimate(points)\n",
        "\n",
        "        # RANSAC\n",
        "        model_RANSAC, _ = ransac(points, LineModelND, min_samples=2, residual_threshold=5, max_trials=n_trials)\n",
        "\n",
        "        # compute lines\n",
        "        x_range = np.array([x_curs.min(), x_curs.max()])\n",
        "        y_range = model_LMND.predict_y(x_range)\n",
        "        y_range_RANSAC = model_RANSAC.predict_y(x_range)\n",
        "        slope = (y_range_RANSAC[1] - y_range_RANSAC[0])/(x_range[1]- x_range[0])\n",
        "\n",
        "        # TODO: We need a better way to recognize unseen walls.\n",
        "\n",
        "        # store angle\n",
        "        angs.append(np.arctan(slope))   \n",
        "\n",
        "    angs = np.array(angs)\n",
        "    angs[angs > 1.5] = angs[angs > 1.5]-np.pi\n",
        "\n",
        "    print('Total time: %fs' % (time()-startTime))\n",
        "    \n",
        "    return angs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# search for corners from angles (DEPRECATED)\n",
        "def find_corners_from_angles(angs, x_data, y_data):\n",
        "\n",
        "    # corners based on thersholding\n",
        "    corner_idx = np.abs(np.diff(angs)) > 0.8\n",
        "\n",
        "    # arbitrary offset indexing\n",
        "    # TODO: Use other heuristics to determine centering!\n",
        "    offset = -1\n",
        "\n",
        "    n_win = len(x_data) - len(corner_idx)\n",
        "\n",
        "    # set up logical indexing window\n",
        "    corner_idx = np.concatenate(([False]*(int(n_win/2)-offset), corner_idx, [False]*(int(n_win/2)+1+offset)))\n",
        "\n",
        "    # retrieve corner guesses\n",
        "    x_corner = x_data[corner_idx]\n",
        "    y_corner = y_data[corner_idx]\n",
        "\n",
        "    # plot corner point guesses\n",
        "\n",
        "    plt.plot(x_data, y_data, '.')\n",
        "    plt.plot(x_corner, y_corner, 'o')\n",
        "    plt.title('Corner Guessing')\n",
        "    plt.legend(['Raw data', 'Corner guess'])\n",
        "    plt.axis('equal')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def distance(x1,y1,x2,y2):\n",
        "    # compute cartesian distance\n",
        "    return np.sqrt((x1-x2)**2 + (y1-y2)**2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# compute intersection of two lines\n",
        "def line_intersection(line1, line2):\n",
        "    xdiff = (line1[0][0] - line1[1][0], line2[0][0] - line2[1][0])\n",
        "    ydiff = (line1[0][1] - line1[1][1], line2[0][1] - line2[1][1])\n",
        "\n",
        "    def det(a, b):\n",
        "        return a[0] * b[1] - a[1] * b[0]\n",
        "\n",
        "    div = det(xdiff, ydiff)\n",
        "    if div == 0:\n",
        "       raise Exception('lines do not intersect')\n",
        "\n",
        "    d = (det(*line1), det(*line2))\n",
        "    x = det(d, xdiff) / div\n",
        "    y = det(d, ydiff) / div\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pad array\n",
        "def fill_arr(arr, val, n, offset=0):\n",
        "    fill_n = n - len(arr)\n",
        "    ret = np.concatenate(([val]*int(np.floor(fill_n/2)+offset), arr, [val]*int(np.ceil(fill_n/2)-offset)))\n",
        "    return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# look for angle regions where we are transitioning from one wall to another\n",
        "def search_transition_regions(angs, slide_win=40, angle_threshold=0.8, count_thresh=1, verbose=False):\n",
        "    trans_idx = np.abs(np.diff(angs)) > angle_threshold\n",
        "    trans_slide = []\n",
        "    \n",
        "    # loop to find regions of high counts of transitions\n",
        "    for idx in range(len(trans_idx)-slide_win):        \n",
        "        trans_slide.append(np.sum(trans_idx[idx:(idx+slide_win)])>count_thresh)\n",
        "\n",
        "    if verbose:\n",
        "        plt.plot(trans_idx, '.')\n",
        "        plt.plot(trans_slide)\n",
        "        plt.legend(['Transition indicator', 'Transition moving OR'])\n",
        "        plt.show()\n",
        "        \n",
        "    return trans_slide"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# clean the wall predictions using RANSAC\n",
        "def compile_walls(trans_slide, x_data, y_data, n_trials=100, verbose=False):\n",
        "    # the idea of this function is to compute RANSAC lines on stable regions (walls) as opposed to unstable corners\n",
        "\n",
        "    offset = 1\n",
        "\n",
        "    # pad array to full data length\n",
        "    trans_fill = fill_arr(trans_slide, False, len(x_data), offset=offset)\n",
        "\n",
        "    # pairwise XOR (exclusive or), looking for changes in transition regions\n",
        "    t_idx = [trans_fill[i] != trans_fill[i+1] for i in range(len(trans_fill)-1)]\n",
        "\n",
        "    # reassemble these segment points \n",
        "    seg_pts = np.concatenate(([0], np.where(t_idx)[0], [len(x_data)-1]))\n",
        "\n",
        "    it = iter(seg_pts)\n",
        "    wall_lines = []\n",
        "\n",
        "    # loop through wall segments (two points at a time as a line needs two points)\n",
        "    for p1 in it:\n",
        "        p2 = next(it)\n",
        "\n",
        "        # cut window\n",
        "        x_curs = x_data[p1:p2]\n",
        "        y_curs = y_data[p1:p2]\n",
        "\n",
        "        # ignore small segments\n",
        "        if len(x_curs) < 5:\n",
        "            continue\n",
        "\n",
        "        # setup RANSAC\n",
        "        model_LMND = LineModelND()\n",
        "        points = np.column_stack([x_curs, y_curs])\n",
        "        model_LMND.estimate(points)\n",
        "\n",
        "        # RANSAC\n",
        "        model_RANSAC, _ = ransac(points, LineModelND, min_samples=2, residual_threshold=5, max_trials=n_trials)\n",
        "\n",
        "        # compute lines\n",
        "        x_range = np.array([x_curs.min(), x_curs.max()])\n",
        "        y_range = model_LMND.predict_y(x_range)\n",
        "        y_range_RANSAC = model_RANSAC.predict_y(x_range)\n",
        "        slope = (y_range_RANSAC[1] - y_range_RANSAC[0])/(x_range[1]- x_range[0])\n",
        "        \n",
        "        y_range_robust = model_RANSAC.predict_y(x_range)\n",
        "        k = (y_range_robust[1] - y_range_robust[0])/(x_range[1]- x_range[0])\n",
        "\n",
        "        m = y_range_robust[0] - k*x_range[0]\n",
        "        x0 = (y_curs.min() - m)/k\n",
        "        x1 = (y_curs.max() - m)/k\n",
        "        x_range_y = np.array([x0, x1])\n",
        "        y_range_robust_y = model_RANSAC.predict_y(x_range_y)\n",
        "        ww = (y_range_robust_y[1] - y_range_robust_y[0]) / (x_range_y[1] - x_range_y[0])\n",
        "\n",
        "        if (distance(x_range[0], y_range_robust[0], x_range[1], y_range_robust[1]) <\n",
        "        distance(x_range_y[0], y_range_robust_y[0], x_range_y[1], y_range_robust_y[1])):            \n",
        "            x_range_r = x_range\n",
        "            y_range_r = y_range_robust\n",
        "        else:\n",
        "            plt.plot(x_range_y, y_range_robust_y, '-r', label='Robust line model')\n",
        "            x_range_r = x_range_y\n",
        "            y_range_r = y_range_robust_y\n",
        "        \n",
        "        # what is the absolute distance the wall spans?\n",
        "        x_span = np.abs(x_range_r[1] - x_range_r[0])\n",
        "        y_span = np.abs(y_range_r[1] - y_range_r[0])\n",
        "\n",
        "        if verbose:\n",
        "            plt.scatter(x_data, y_data)\n",
        "            plt.scatter(x_curs, y_curs)\n",
        "            plt.plot(x_range_r, y_range_r, '-r', label='Robust line model')\n",
        "            plt.axis('equal')\n",
        "            plt.show()\n",
        "            print('x_span: %f, y_span: %f' % (x_span, y_span))\n",
        "\n",
        "        # do not record if span is too small (tiny walls can be unstable)\n",
        "        if x_span < 200 and y_span < 200:\n",
        "            continue\n",
        "\n",
        "        # record wall line points (these are arbitrary and are not end points!)\n",
        "        p1 = np.array((x_range_r[0], y_range_r[0]))\n",
        "        p2 = np.array((x_range_r[1], y_range_r[1]))\n",
        "        wall_lines.append((p1, p2))\n",
        "            \n",
        "    wall_lines = np.array(wall_lines)\n",
        "    return wall_lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_slope(p1, p2):\n",
        "    return (p2[1]-p1[1]) / (p2[0]-p1[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get corners from walls\n",
        "def get_wall_corners(wall_lines):\n",
        "    sects = []\n",
        "    for i in range(len(wall_lines)-1):\n",
        "        l1 = wall_lines[i]\n",
        "        l2 = wall_lines[i+1]\n",
        "        m1 = get_slope(l1[0], l1[1])\n",
        "        m2 = get_slope(l2[0], l2[1])\n",
        "        if np.abs(m1-m2) < 0.1:\n",
        "            continue\n",
        "        sect = line_intersection(l2, l1)\n",
        "        sects.append(sect)\n",
        "    sects = np.array(sects)\n",
        "    return sects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot a line\n",
        "def plot_line(ll, tag_append='r'):\n",
        "    plt.plot(ll[:, 0], ll[:, 1], '%s-' % tag_append)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot corners\n",
        "def plot_corners(sects, x_data, y_data):\n",
        "    sects_cat = np.vstack((sects, sects[0,:]))\n",
        "    plt.plot(x_data, y_data, '.')\n",
        "    plt.plot(sects[:,0], sects[:,1], 'o')\n",
        "    plt.plot(sects_cat[:,0], sects_cat[:,1], 'r-', alpha=0.5)\n",
        "    plt.plot()\n",
        "    plt.axis('equal')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# compute wall lengths\n",
        "def compute_wall_lengths(sects, verbose=False):\n",
        "\n",
        "    # compute the lengths of the walls from the corners\n",
        "\n",
        "    sects_cat = np.vstack((sects, sects[0,:]))\n",
        "    lengths = []\n",
        "\n",
        "    # loop through corners two at a time\n",
        "    for i in range(len(sects_cat)-1):\n",
        "        p1 = sects_cat[i, :]\n",
        "        p2 = sects_cat[i+1, :]\n",
        "        # compute and save wall length\n",
        "        lengths.append(distance(p1[0], p1[1], p2[0], p2[1]))\n",
        "\n",
        "    if verbose:\n",
        "        plt.figure()\n",
        "        for i in range(len(sects_cat)-1):\n",
        "            cur_x = sects_cat[i:(i+2),0]\n",
        "            cur_y = sects_cat[i:(i+2),1]\n",
        "            plt.plot(cur_x, cur_y)\n",
        "            plt.text(np.mean(cur_x), np.mean(cur_y), '%d' % lengths[i])\n",
        "        plt.axis('equal')\n",
        "        plt.show()\n",
        "\n",
        "    return lengths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_polygon_area(x, y):\n",
        "    return 0.5*np.abs(np.dot(x,np.roll(y,1))-np.dot(y,np.roll(x,1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# compute moving average\n",
        "def moving_average(a, n=10) :\n",
        "    ret = np.cumsum(a, dtype=float)\n",
        "    ret[n:] = ret[n:] - ret[:-n]\n",
        "    return ret[n - 1:] / n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# compute moving standard deviation\n",
        "def moving_std(a, n=10):\n",
        "    ret = np.zeros(len(a)-n+1)\n",
        "    for i in range(len(a)-n+1):\n",
        "        ret[i] = np.std(a[i:(i+n-1)])\n",
        "    return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# this function finds the centroid of a line segment and then computes a perpendicular line\n",
        "def find_perpendicular_bisector(in_line, verbose=False):\n",
        "    a = in_line[0]\n",
        "    b = in_line[1]\n",
        "    midpoint = (np.mean((b[0], a[0])), np.mean((b[1], a[1])))\n",
        "    slope = (b[1]-a[1]) / (b[0]-a[0])\n",
        "    bslope = -1/slope\n",
        "    c = midpoint\n",
        "    d = (midpoint[0]+1, midpoint[1]+bslope)\n",
        "    ret = np.array((c, d))\n",
        "    if verbose:\n",
        "        plot_line(in_line, 'r')\n",
        "        plot_line(c_d, 'g')\n",
        "        plt.axis('equal')\n",
        "        plt.show()\n",
        "\n",
        "    return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def intersect_ls(P0,P1):\n",
        "    \"\"\"P0 and P1 are NxD arrays defining N lines.\n",
        "    D is the dimension of the space. This function \n",
        "    returns the least squares intersection of the N\n",
        "    lines from the system given by eq. 13 in \n",
        "    http://cal.cs.illinois.edu/~johannes/research/LS_line_intersect.pdf.\n",
        "    \"\"\"\n",
        "    # generate all line direction vectors \n",
        "    n = (P1-P0)/np.linalg.norm(P1-P0,axis=1)[:,np.newaxis] # normalized\n",
        "\n",
        "    # generate the array of all projectors \n",
        "    projs = np.eye(n.shape[1]) - n[:,:,np.newaxis]*n[:,np.newaxis]  # I - n*n.T\n",
        "    # see fig. 1 \n",
        "\n",
        "    # generate R matrix and q vector\n",
        "    R = projs.sum(axis=0)\n",
        "    q = (projs @ P0[:,:,np.newaxis]).sum(axis=0)\n",
        "\n",
        "    # solve the least squares problem for the \n",
        "    # intersection point p: Rp = q\n",
        "    ret = np.linalg.lstsq(R,q,rcond=None)[0]\n",
        "\n",
        "    return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# detect round objects\n",
        "def detect_pillar(x, y, verbose=False):\n",
        "\n",
        "    # smooth the data with a moving average\n",
        "    x_ma = moving_average(x, 5)\n",
        "    y_ma = moving_average(y, 5)\n",
        "    ps = np.vstack((x_ma, y_ma)).T\n",
        "\n",
        "    # copy points into two pieces offset by one (we want to loop through adjacent points)\n",
        "    p0 = ps[0:-1, :]\n",
        "    p1 = ps[1:, :]\n",
        "\n",
        "    b0 = []\n",
        "    b1 = []\n",
        "\n",
        "    # compute perpendicular bisectors on each line segment in set\n",
        "    for pp0, pp1 in zip(p0, p1):\n",
        "        ppb = find_perpendicular_bisector((pp0, pp1))\n",
        "        b0.append(ppb[0])\n",
        "        b1.append(ppb[1])\n",
        "\n",
        "    b0 = np.array(b0)\n",
        "    b1 = np.array(b1)\n",
        "\n",
        "    # compute common intersection (if any)\n",
        "    p = intersect_ls(b0, b1)\n",
        "\n",
        "    # compute best guess radius\n",
        "    distances = (distance(b0[:,0], b0[:,1], p[0], p[1]))\n",
        "    radius = np.mean(distances)\n",
        "\n",
        "    # residual squared\n",
        "    heu = np.mean((distances-radius)**2)\n",
        "\n",
        "    if verbose:\n",
        "        print('Mid: (%f, %f), Radius: %f, Heu: %f' % (p[0], p[1], radius, heu))\n",
        "        plt.plot(x_ma, y_ma, '.')\n",
        "        plt.plot(p[0], p[1], 'o')\n",
        "        cc = plt.Circle(p, radius, color='g', fill=False)\n",
        "        ax = plt.gca()\n",
        "        ax.add_artist(cc)\n",
        "        plt.axis('equal')\n",
        "        plt.show()\n",
        "\n",
        "    # return true if residuals are low\n",
        "    return heu < 150, p, radius"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# attempt to fit points to line\n",
        "def fit_points_to_line(p1, p2, xs):\n",
        "    m = (p2[1]-p1[1]) / (p2[0]-p1[0])\n",
        "    x_diffs = xs - p1[0]\n",
        "    return m*x_diffs + p1[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# compute nearest distance from point to line\n",
        "def perpendicular_distance(p1, p2, p3):\n",
        "    # distance of p3 to line defined by p1 and p2\n",
        "    return np.linalg.norm(np.cross(p2-p1, p1-p3))/np.linalg.norm(p2-p1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mHtqW0sqgpwd"
      },
      "source": [
        "### Old sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#x_data, y_data = read_capture('scan-data-Room2-upto-50times.csv')\n",
        "#angs = compute_ransac_angles(x_data, y_data)\n",
        "#find_corners_from_angles(angs, x_data, y_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#x_data, y_data = read_capture('capture2.csv')\n",
        "#angs = compute_ransac_angles(x_data, y_data)\n",
        "#find_corners_from_angles(angs, x_data, y_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#from scipy.signal import savgol_filter\n",
        "#x = np.linspace(0,2*np.pi,100)\n",
        "#y = np.sin(x) + np.random.random(100) * 0.2\n",
        "#yhat = savgol_filter(y, 51, 3) # window size 51, polynomial order 3\n",
        "#\n",
        "#plt.plot(x,y)\n",
        "#plt.plot(x,yhat, color='red')\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tx4Ch1CTwIKR"
      },
      "source": [
        "## Class style"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# convert radial coordinates to cartesian\n",
        "def rad2cart(angle, distance):\n",
        "    cartesian = [( r*math.sin(phi*math.pi/180),r*math.cos(phi*math.pi/180)) for r, phi in zip(distance, angle)]\n",
        "    x, y = map(list, zip(*cartesian))\n",
        "    x = np.array(x)\n",
        "    y = np.array(y)\n",
        "\n",
        "    return x.reshape(-1, 1), y.reshape(-1, 1)\n",
        "\n",
        "# this is the data container\n",
        "class LidarData():\n",
        "\n",
        "    # initialize data\n",
        "    def __init__(self, file_path):\n",
        "        df = pd.read_csv(file_path, delimiter=',', header=None)\n",
        "        self.angle = df.values[:, 0]\n",
        "        self.distance = df.values[:, 1]\n",
        "        self.reset_xy()\n",
        "        self.pillars = []\n",
        "        print('Read %d points from %s' % (len(self.angle), file_path))\n",
        "\n",
        "    # recompute cartesian\n",
        "    def reset_xy(self):\n",
        "        self.x, self.y = rad2cart(self.angle, self.distance)\n",
        "\n",
        "    # plot cartesian\n",
        "    def plot_xy(self, show_pillars=False):\n",
        "        plt.plot(self.x, self.y, '.', color = 'grey')\n",
        "        ax = plt.gca()\n",
        "        if show_pillars:\n",
        "            for pp in self.pillars:\n",
        "                print(pp)\n",
        "                cc = plt.Circle(pp[0], pp[1], color='g', fill=False)        \n",
        "                ax.add_artist(cc)\n",
        "        \n",
        "        plt.title('All Data')\n",
        "        plt.axis('equal')\n",
        "        plt.show()\n",
        "\n",
        "    # enforce maximum range\n",
        "    def apply_max_range(self, max_range=10000):\n",
        "        # cull all values greater than a certain range\n",
        "        in_idx = self.distance < max_range\n",
        "        print('apply_max_range: %d points to %d' % (len(self.angle), sum(in_idx)))\n",
        "        self.angle = self.angle[in_idx]\n",
        "        self.distance = self.distance[in_idx]\n",
        "        self.reset_xy()\n",
        "\n",
        "    # collapse to unique angles and adopt their means while culling unstable angles\n",
        "    def mean_and_filter_angles(self, std_thresh=0.0001):\n",
        "        # the purpose of this function is to average the distance measures for each angle\n",
        "        # averaged values are more robust\n",
        "        # if the standard deviation is too high, that angle is deemed unstable and is dropped\n",
        "        unique_angles = np.unique(self.angle)\n",
        "        avgs = np.zeros(len(unique_angles))\n",
        "        stds = np.zeros(len(unique_angles))\n",
        "        for idx, a in enumerate(unique_angles):\n",
        "            cur_idx = self.angle == a\n",
        "            cur_dis = self.distance[cur_idx]\n",
        "            avgs[idx] = np.mean(cur_dis)\n",
        "            stds[idx] = np.std(cur_dis)\n",
        "        valid_idx = stds < std_thresh\n",
        "        print('mean_and_filter_angles: %d points to %d' % (len(self.angle), sum(valid_idx)))\n",
        "        self.angle = unique_angles[valid_idx]\n",
        "        self.distance = avgs[valid_idx]\n",
        "        self.reset_xy()\n",
        "\n",
        "    # remove isolated readings\n",
        "    def remove_lone_points(self, dis_thresh=100):\n",
        "        # search for and remove points with no neighbors (high chance of outlier)\n",
        "        range_diff = np.abs(np.diff(self.distance))\n",
        "        high_idx = range_diff > dis_thresh\n",
        "        lone_idx = [high_idx[i] and high_idx[i+1] for i in range(len(range_diff)-1)]\n",
        "        lone_idx = np.concatenate(([False], lone_idx, [False]))\n",
        "        print('remove_lone_points: %d points to %d' % (len(self.angle), sum(~lone_idx)))\n",
        "        self.angle = self.angle[~lone_idx]\n",
        "        self.distance = self.distance[~lone_idx]\n",
        "        self.reset_xy()\n",
        "\n",
        "    # remove small point clusters\n",
        "    def remove_small_clusters(self, eps=500, min_samples=20, verbose=False):\n",
        "        # remove clusters with no neighbors (high chance of non-wall)\n",
        "        X = np.hstack((self.x, self.y))\n",
        "        dbscan = DBSCAN(eps=eps, min_samples=min_samples)        \n",
        "        clusters = dbscan.fit_predict(X)\n",
        "        if verbose:\n",
        "            # plot the cluster assignments\n",
        "            plt.scatter(X[:, 0], X[:, 1], c=clusters, cmap=\"plasma\")\n",
        "            plt.xlabel(\"x\")\n",
        "            plt.ylabel(\"y\")\n",
        "            plt.axis('equal')\n",
        "            plt.show()\n",
        "\n",
        "        valid_idx = clusters > -1\n",
        "        print('remove_small_clusters: %d points to %d' % (len(self.angle), sum(valid_idx)))\n",
        "        self.angle = self.angle[valid_idx]\n",
        "        self.distance = self.distance[valid_idx]\n",
        "        self.reset_xy()\n",
        "\n",
        "    # remove distant clusters\n",
        "    def remove_pillars(self, min_samples=10, verbose=False):\n",
        "        # search for round walls and remove them\n",
        "        # this function has hard coding which can be tuned to be more lenient in allowing round objects\n",
        "        X = np.hstack((self.x, self.y))\n",
        "        scaler = StandardScaler()\n",
        "        X_scaled = scaler.fit_transform(X)\n",
        "        dbscan = DBSCAN(eps=0.05, min_samples=min_samples)        \n",
        "        clusters = dbscan.fit_predict(X_scaled)\n",
        "\n",
        "        if verbose:\n",
        "            # plot the cluster assignments\n",
        "            plt.scatter(X[:, 0], X[:, 1], c=clusters, cmap=\"plasma\")\n",
        "            plt.xlabel(\"x\")\n",
        "            plt.ylabel(\"y\")\n",
        "            plt.axis('equal')\n",
        "            plt.show()\n",
        "\n",
        "        invalid = []\n",
        "        # loop through clusters found be DBSCAN\n",
        "        for cc in np.unique(clusters):\n",
        "            if cc == -1:\n",
        "                continue\n",
        "            c_idx = cc == clusters\n",
        "            # deterine if region lies on an arc\n",
        "            is_pillar, mid, rad = detect_pillar(self.x[c_idx], self.y[c_idx], verbose=verbose)\n",
        "            if is_pillar:\n",
        "                self.pillars.append((mid, rad))            \n",
        "                invalid.append(cc)\n",
        "\n",
        "        # mark arcs as invalid walls\n",
        "        valid_idx = clusters > -1\n",
        "        for cc in invalid:\n",
        "            valid_idx[cc==clusters] = False\n",
        "\n",
        "        print('remove_pillars: %d points to %d' % (len(self.angle), sum(valid_idx)))\n",
        "        self.angle = self.angle[valid_idx]\n",
        "        self.distance = self.distance[valid_idx]\n",
        "        self.reset_xy()\n",
        "\n",
        "    # apply all valid preprocessing cleanup\n",
        "    def apply_all_cleaning(self, verbose=False):\n",
        "        self.apply_max_range()\n",
        "        self.mean_and_filter_angles()\n",
        "        self.remove_lone_points()\n",
        "        self.remove_small_clusters(verbose=verbose)\n",
        "        self.remove_pillars(verbose=verbose)\n",
        "            "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "i7ofkcqcAUZ6"
      },
      "source": [
        "### Class examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# read and clean data\n",
        "ld1 = LidarData('scan-data-Room1-upto-50times.csv')\n",
        "ld1.plot_xy()\n",
        "ld1.apply_all_cleaning(verbose=True)\n",
        "ld1.plot_xy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# compute preliminary wall angles\n",
        "angs = compute_ransac_angles(ld1.x, ld1.y, n_win=300, n_trials=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# search for wall transition regions (corners)\n",
        "trans_slide = search_transition_regions(angs, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# compute more robust wall estimations in stable regions\n",
        "wall_lines = compile_walls(trans_slide, ld1.x, ld1.y, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# find corners from robust walls\n",
        "sects = get_wall_corners(wall_lines)\n",
        "plot_corners(sects, ld1.x, ld1.y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get floor plan\n",
        "lengths = compute_wall_lengths(sects, verbose=True)\n",
        "print('Wall length: %f' % np.sum(lengths))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# total area\n",
        "area = compute_polygon_area(sects[:,0], sects[:,1])\n",
        "print('Floor area: %f' % area)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# read and clean data\n",
        "ld2 = LidarData('scan-data-Room2-upto-50times.csv')\n",
        "ld2.plot_xy()\n",
        "ld2.apply_all_cleaning(verbose=True)\n",
        "ld2.plot_xy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# compute preliminary wall angles\n",
        "angs = compute_ransac_angles(ld2.x, ld2.y, n_win=25, n_trials=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# search for wall transition regions (corners)\n",
        "trans_slide = search_transition_regions(angs, slide_win=10, angle_threshold=0.3, count_thresh=0, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# recompute walls in stable regions\n",
        "wall_lines = compile_walls(trans_slide, ld2.x, ld2.y, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# find corners from walls\n",
        "sects = get_wall_corners(wall_lines)\n",
        "plot_corners(sects, ld2.x, ld2.y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get floor plan\n",
        "lengths = compute_wall_lengths(sects, verbose=True)\n",
        "print('Wall length: %f' % np.sum(lengths))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# total area\n",
        "area = compute_polygon_area(sects[:,0], sects[:,1])\n",
        "print('Floor area: %f' % area)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "JkcYknSupf52"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ]
}