{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#read scanned data from text file\n",
    "\n",
    "df = pd.read_csv('capture1.csv',delimiter=',')\n",
    "x = df.values[:,0]\n",
    "y = df.values[:,1]\n",
    "#print(x,y)\n",
    "\n",
    "df = pd.read_csv('capture1.csv',delimiter=',')\n",
    "angle = df.values[:,0]\n",
    "#print(angle)\n",
    "distance = df.values[:,1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#polar to cartesian converison\n",
    "cartesian = [(r*math.cos(phi*math.pi/180), r*math.sin(phi*math.pi/180)) for r, phi in zip(distance, angle)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#shift to all positive value\n",
    "x, y = map(list, zip(*cartesian))\n",
    "x=  np.array(x)\n",
    "y=  np.array(y)\n",
    "\n",
    "x+=  x.min()*-1\n",
    "y+=  y.min()*-1\n",
    "\n",
    "print(y.min())\n",
    "\n",
    "data = np.vstack([y, x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###only for matplotLib\n",
    "\n",
    "#plt.scatter(y,x, color='yellowgreen', marker='.',label='Inliers')\n",
    "plt.scatter(y,x)\n",
    "\n",
    "###remove the axis tag from here\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "\n",
    "#plt.scatter(y,x)\n",
    "plt.savefig('floor.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "### canny edge detection\n",
    "\n",
    "image = cv.imread('floor.png')\n",
    "original = image.copy()\n",
    "gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "'''\n",
    "cv.imshow(\"gray\",gray)\n",
    "cv.waitKey(1000)\n",
    "cv.destroyAllWindows()\n",
    "'''\n",
    "canny = cv.Canny(gray,100,200)\n",
    "\n",
    "\n",
    "## creating mask to hide axis\n",
    "\n",
    "'''\n",
    "Here's a simple approach:\n",
    "\n",
    "Convert image to grayscale\n",
    "Color threshold to isolate green\n",
    "Find contours and fill in mask\n",
    "Bitwise-and to get result\n",
    "https://stackoverflow.com/questions/57940737/how-to-mask-everything-in-an-image-except-for-a-specific-color-inside\n",
    "'''\n",
    "\n",
    "lower = np.array([35, 0, 0], dtype=\"uint8\")\n",
    "upper = np.array([131, 255, 185], dtype=\"uint8\")\n",
    "mask = cv.inRange(image, lower, upper)\n",
    "\n",
    "cnts = cv.findContours(mask, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "cv.fillPoly(mask, cnts, (255,255,255))\n",
    "result = cv.bitwise_and(original,original,mask=mask)\n",
    "\n",
    "\n",
    "cv.imshow(\"result\",result)\n",
    "cv.waitKey(10000)\n",
    "cv.destroyAllWindows()\n",
    "###Hough transform\n",
    "\n",
    "#gray = cv.cvtColor(result,cv.COLOR_BGR2GRAY)\n",
    "#print(gray)\n",
    "edges = cv.Canny(gray,50,150,apertureSize = 3)\n",
    "minLineLength = 100\n",
    "maxLineGap = 10\n",
    "lines = cv.HoughLinesP(edges,1,np.pi/180,100,minLineLength,maxLineGap)\n",
    "\n",
    "for x1,y1,x2,y2 in lines[0]:\n",
    "    cv.line(image,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "#cv.imwrite('houghlines5.jpg',image)\n",
    "\n",
    "\n",
    "cv.imshow(\"canny\",image)\n",
    "cv.waitKey(10000)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method min of numpy.ndarray object at 0x0000025F02B7F6C0> <built-in method max of numpy.ndarray object at 0x0000025F02B7F6C0>\n",
      "(2, 578)\n",
      "[[13338.4869863  13352.59933404 13355.11943502 ... 13368.99510942\n",
      "  13355.08926901 13341.58158014]\n",
      " [ 4210.11908019  4267.68497587  4325.20778625 ...  3921.44737629\n",
      "   3979.5308153   4037.28251182]]\n"
     ]
    }
   ],
   "source": [
    "###### coverting this into 2d array\n",
    "\n",
    "#x=x.reshape( 1,-1)\n",
    "\n",
    "#print(x)\n",
    "#y=y.reshape(1,-1)\n",
    "print(x.min, x.max)\n",
    "\n",
    "# generate coordinates of line\n",
    "#x = np.arange(-200, 200)\n",
    "\n",
    "#y = 0.2 * x + 20\n",
    "data = np.vstack([x, y])\n",
    "print(data.shape)\n",
    "print(data)\n",
    "img = np.zeros([100,100,3],dtype=np.uint8)\n",
    "cv.imshow(\"data\",data)\n",
    "cv.waitKey(1000)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% houghlineP is implementing here\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('floor.png')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "thresh = cv2.threshold(gray, 0, 255,cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9,9))\n",
    "close = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=3)\n",
    "\n",
    "minLineLength = 750\n",
    "maxLineGap = 0\n",
    "lines = cv2.HoughLinesP(close,1,np.pi/180,100,minLineLength,maxLineGap)\n",
    "for line in lines:\n",
    "    for x1,y1,x2,y2 in line:\n",
    "        cv2.line(image,(x1,y1),(x2,y2),(36,255,12),3)\n",
    "\n",
    "cv2.imshow('thresh', thresh)\n",
    "cv2.imshow('close', close)\n",
    "cv2.imshow('image', image)\n",
    "cv2.waitKey(1000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6abaadc0f624>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;31m#your answer image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0mimg2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;31m#for every component in the image, you keep it only if it's above min_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_components\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "#Import packages\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Import utilites\n",
    "#from utils import label_map_util\n",
    "#from utils import visualization_utils as vis_util\n",
    "\n",
    "# Name of the directory containing the object detection module we're using\n",
    "#MODEL_NAME = 'inference_graph'\n",
    "IMAGE_NAME = 'floor.png'\n",
    "#Remove Small Items\n",
    "im_gray = cv2.imread(IMAGE_NAME, cv2.IMREAD_GRAYSCALE)\n",
    "(thresh, im_bw) = cv2.threshold(im_gray, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "thresh = 127\n",
    "im_bw = cv2.threshold(im_gray, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "#find all your connected components \n",
    "nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(im_bw, connectivity=8)\n",
    "#connectedComponentswithStats yields every seperated component with information on each of them, such as size\n",
    "#the following part is just taking out the background which is also considered a component, but most of the time we don't want that.\n",
    "sizes = stats[1:, -1]; nb_components = nb_components - 1\n",
    "\n",
    "# minimum size of particles we want to keep (number of pixels)\n",
    "#here, it's a fixed value, but you can set it as you want, eg the mean of the sizes or whatever\n",
    "min_size = 150  \n",
    "\n",
    "#your answer image\n",
    "img2 = np.zeros((output.shape))\n",
    "#for every component in the image, you keep it only if it's above min_size\n",
    "for i in range(0, nb_components):\n",
    "    if sizes[i] >= min_size:\n",
    "        img2[output == i + 1] = 255\n",
    "\n",
    "cv2.imshow('room detector', img2)\n",
    "#MorphologicalTransform\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "dilation = cv2.dilate(img2, kernel)\n",
    "erosion = cv2.erode(img2, kernel, iterations=6)\n",
    "\n",
    "#cv2.imshow(\"img2\", img2)\n",
    "cv2.imshow(\"Dilation\", dilation)\n",
    "#cv2.imwrite(\"Dilation.jpg\", dilation)\n",
    "#cv2.imshow(\"Erosion\", erosion)\n",
    "image = dilation\n",
    "#image = cv2.imread('floortest2.PNG')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#thresh = cv2.threshold(gray, 0, 255,cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "#kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9,9))\n",
    "#close = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=3)\n",
    "\n",
    "minLineLength = 550\n",
    "maxLineGap = 60\n",
    "lines = cv2.HoughLinesP(close,1,np.pi/180,100,minLineLength,maxLineGap)\n",
    "for line in lines:\n",
    "    for x1,y1,x2,y2 in line:\n",
    "        cv2.line(image,(x1,y1),(x2,y2),(36,255,12),3)\n",
    "\n",
    "cv2.imshow('thresh', thresh)\n",
    "cv2.imshow('close', close)\n",
    "cv2.imshow('image', image)\n",
    "cv2.waitKey(10000)\n",
    "cv2.destroyAllWindows()\n",
    "# Press any key to close the image\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Clean up\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LineModelND' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-0d08b4e34533>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLineModelND\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx1\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LineModelND' is not defined"
     ]
    }
   ],
   "source": [
    "model = LineModelND()\n",
    "model.estimate(data)\n",
    "x1= np.arange(100,100)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "print(model.params)\n",
    "ax.plot(data[:,0], data[:,1], '.r')\n",
    "ax.plot(x1, model.predict_y(x1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ax.plot(x1, model.predict_y(x1), '-b')\n",
    "mode_robust, inliers = ransac (data, LineModelND, min_samples= 2, \n",
    "                               residual_threshold=2,\n",
    "                               \n",
    "                               \n",
    "                               max_trials=1500)\n",
    "\n",
    "outliers= (inliers== False)\n",
    "print(data)\n",
    "print(data[inliers])\n",
    "x= mode_robust.predict_y(x1)\n",
    "ax.plot(x1, x, '-y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "w, h = 512, 512\n",
    "data = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "data[0:256, 0:256] = [255, 0, 0] # red patch in upper left\n",
    "img = Image.fromarray(data, 'RGB')\n",
    "img.save('my.png')\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}